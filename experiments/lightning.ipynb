{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightning.pytorch as pl\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from umap.umap_ import find_ab_params\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from singleVis.custom_weighted_random_sampler import CustomWeightedRandomSampler\n",
    "from singleVis.vis_models import vis_models as vmodels\n",
    "from singleVis.losses import UmapLoss, ReconstructionLoss, SingleVisLoss, LocalTemporalLoss, SmoothnessLoss\n",
    "from singleVis.edge_dataset import DVIDataHandler, LocalTemporalDataHandler\n",
    "from singleVis.trainer import SingleVisTrainer, LocalTemporalTrainer\n",
    "from singleVis.data import NormalDataProvider\n",
    "from singleVis.spatial_edge_constructor import LocalSpatialTemporalEdgeConstructor, SingleEpochSpatialEdgeConstructor\n",
    "from singleVis.projector import DVIProjector\n",
    "from singleVis.eval.evaluator import Evaluator\n",
    "from singleVis.visualizer import visualizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LitInstanceNormAE(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, encoder_dims, decoder_dims, criterion):\n",
    "        super(LitInstanceNormAE, self).__init__()\n",
    "        self.criterion = criterion\n",
    "  \n",
    "        assert len(encoder_dims) > 1\n",
    "        assert len(decoder_dims) > 1\n",
    "        self.encoder_dims = encoder_dims\n",
    "        self.decoder_dims = decoder_dims\n",
    "\n",
    "        # Build Encoder\n",
    "        modules = list()\n",
    "        for i in range(0, len(self.encoder_dims)-2):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                nn.Linear(self.encoder_dims[i], self.encoder_dims[i+1]),\n",
    "                nn.InstanceNorm1d(self.encoder_dims[i+1]),\n",
    "                nn.ReLU(True) \n",
    "                )\n",
    "            )\n",
    "        modules.append(nn.Linear(self.encoder_dims[-2], self.encoder_dims[-1]))\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = list()\n",
    "        for i in range(0, len(self.decoder_dims)-2):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(self.decoder_dims[i], self.decoder_dims[i+1]),\n",
    "                    nn.InstanceNorm1d(self.decoder_dims[i+1]),\n",
    "                    nn.ReLU(True)\n",
    "                )\n",
    "                \n",
    "            )\n",
    "        modules.append(nn.Linear(self.decoder_dims[-2], self.decoder_dims[-1]))\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "    \n",
    "    def forward(self, edge_to, edge_from):\n",
    "        outputs = dict()\n",
    "        embedding_to = self.encoder(edge_to)\n",
    "        embedding_from = self.encoder(edge_from)\n",
    "        recon_to = self.decoder(embedding_to)\n",
    "        recon_from = self.decoder(embedding_from)\n",
    "        \n",
    "        outputs[\"umap\"] = (embedding_to, embedding_from)\n",
    "        outputs[\"recon\"] = (recon_to, recon_from)\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        # edge_to, edge_from, a_to, a_from, coeffi_from, embedded_from = batch\n",
    "\n",
    "        # edge_to = edge_to.to(device=self.DEVICE, dtype=torch.float32)\n",
    "        # edge_from = edge_from.to(device=self.DEVICE, dtype=torch.float32)\n",
    "        # a_to = a_to.to(device=self.DEVICE, dtype=torch.float32)\n",
    "        # a_from = a_from.to(device=self.DEVICE, dtype=torch.float32)\n",
    "        # coeffi_from = coeffi_from.to(device=self.DEVICE, dtype=torch.bool)\n",
    "        # embedded_from = embedded_from.to(device=self.DEVICE, dtype=torch.float32)\n",
    "\n",
    "        # outputs = self.model(edge_to, edge_from)\n",
    "        # _, _, _, loss = self.criterion(edge_to, edge_from, a_to, a_from, coeffi_from, embedded_from, outputs)\n",
    "        edge_to, edge_from, a_to, a_from = batch\n",
    "        edge_to = edge_to.to(dtype=torch.float32)\n",
    "        edge_from = edge_from.to(dtype=torch.float32)\n",
    "        a_to = a_to.to(dtype=torch.float32)\n",
    "        a_from = a_from.to(dtype=torch.float32)\n",
    "\n",
    "        outputs = self.forward(edge_to, edge_from)\n",
    "        _, _, loss = self.criterion(edge_to, edge_from, a_to, a_from, outputs)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Define training parameters\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=.01, weight_decay=1e-5)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=.1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIS_METHOD = \"tDVI\"\n",
    "VIS_MODEL = 'litinAE'\n",
    "CONTENT_PATH = \"/home/xianglin/projects/DVI_data/resnet18_mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(CONTENT_PATH)\n",
    "with open(os.path.join(CONTENT_PATH, \"config.json\"), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config = config[VIS_METHOD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTING = config[\"SETTING\"]\n",
    "CLASSES = config[\"CLASSES\"]\n",
    "DATASET = config[\"DATASET\"]\n",
    "PREPROCESS = config[\"VISUALIZATION\"][\"PREPROCESS\"]\n",
    "GPU_ID = config[\"GPU\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "EPOCH_NAME = config[\"EPOCH_NAME\"]\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "# VIS_MODEL = VISUALIZATION_PARAMETER[\"VIS_MODEL\"]\n",
    "LAMBDA1 = VISUALIZATION_PARAMETER[\"LAMBDA1\"]\n",
    "B_N_EPOCHS = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"B_N_EPOCHS\"]\n",
    "L_BOUND = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"L_BOUND\"]\n",
    "ENCODER_DIMS = VISUALIZATION_PARAMETER[\"ENCODER_DIMS\"]\n",
    "DECODER_DIMS = VISUALIZATION_PARAMETER[\"DECODER_DIMS\"]\n",
    "S_N_EPOCHS = VISUALIZATION_PARAMETER[\"S_N_EPOCHS\"]\n",
    "T_N_EPOCHS = VISUALIZATION_PARAMETER[\"T_N_EPOCHS\"]\n",
    "N_NEIGHBORS = VISUALIZATION_PARAMETER[\"N_NEIGHBORS\"]\n",
    "PATIENT = VISUALIZATION_PARAMETER[\"PATIENT\"]\n",
    "MAX_EPOCH = VISUALIZATION_PARAMETER[\"MAX_EPOCH\"]\n",
    "\n",
    "VIS_MODEL_NAME = VISUALIZATION_PARAMETER[\"VIS_MODEL_NAME\"]\n",
    "EVALUATION_NAME = VISUALIZATION_PARAMETER[\"EVALUATION_NAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import Model.model as subject_model\n",
    "net = eval(\"subject_model.{}()\".format(NET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initialization...\n"
     ]
    }
   ],
   "source": [
    "# Define data_provider\n",
    "data_provider = NormalDataProvider(CONTENT_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, device=DEVICE, classes=CLASSES, epoch_name=EPOCH_NAME, verbose=1)\n",
    "if PREPROCESS:\n",
    "    data_provider._meta_data()\n",
    "    if B_N_EPOCHS >0:\n",
    "        data_provider._estimate_boundary(LEN//10, l_bound=L_BOUND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Losses\n",
    "negative_sample_rate = 5\n",
    "min_dist = .1\n",
    "_a, _b = find_ab_params(1.0, min_dist)\n",
    "umap_loss_fn = UmapLoss(negative_sample_rate, DEVICE, _a, _b, repulsion_strength=1.0)\n",
    "recon_loss_fn = ReconstructionLoss(beta=1.0)\n",
    "smooth_loss_fn = SmoothnessLoss(margin=0.0)\n",
    "# Define Criterion\n",
    "criterion = SingleVisLoss(umap_loss_fn, recon_loss_fn, lambd=LAMBDA1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define visualization models\n",
    "model = LitInstanceNormAE(ENCODER_DIMS, DECODER_DIMS, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Projector\n",
    "projector = DVIProjector(vis_model=model, content_path=CONTENT_PATH, vis_model_name=VIS_MODEL_NAME, epoch_name=EPOCH_NAME, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 27 23:34:25 2023 Building RP forest with 17 trees\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 27 23:34:26 2023 NN descent for 16 iterations\n",
      "\t 1  /  16\n",
      "\t 2  /  16\n",
      "\t 3  /  16\n",
      "\t 4  /  16\n",
      "\tStopping threshold met -- exiting after 4 iterations\n"
     ]
    }
   ],
   "source": [
    "# Define Edge dataset\n",
    "spatial_cons = SingleEpochSpatialEdgeConstructor(data_provider, EPOCH_START, S_N_EPOCHS, B_N_EPOCHS, N_NEIGHBORS, metric=\"euclidean\")\n",
    "edge_to, edge_from, probs, feature_vectors, attention = spatial_cons.construct()\n",
    "\n",
    "dataset = DVIDataHandler(edge_to, edge_from, feature_vectors, attention)\n",
    "\n",
    "n_samples = int(np.sum(S_N_EPOCHS * probs) // 1)\n",
    "# chose sampler based on the number of dataset\n",
    "if len(edge_to) > pow(2,24):\n",
    "    sampler = CustomWeightedRandomSampler(probs, n_samples, replacement=True)\n",
    "else:\n",
    "    sampler = WeightedRandomSampler(probs, n_samples, replacement=True)\n",
    "edge_loader = DataLoader(dataset, batch_size=1000, sampler=sampler, num_workers=4, prefetch_factor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type          | Params\n",
      "--------------------------------------------\n",
      "0 | criterion | SingleVisLoss | 0     \n",
      "1 | encoder   | Sequential    | 174 K \n",
      "2 | decoder   | Sequential    | 175 K \n",
      "--------------------------------------------\n",
      "349 K     Trainable params\n",
      "0         Non-trainable params\n",
      "349 K     Total params\n",
      "1.399     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 379/379 [00:08<00:00, 45.25it/s, v_num=13]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 379/379 [00:08<00:00, 45.17it/s, v_num=13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                        \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                         \t|  -              \t|  13688          \t|  8.7006         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                            \t|  8.3751         \t|  1              \t|  8.3751         \t|  96.26          \t|\n",
      "|  run_training_batch                                                                                                                                            \t|  0.013915       \t|  379            \t|  5.2737         \t|  60.614         \t|\n",
      "|  [LightningModule]LitInstanceNormAE.optimizer_step                                                                                                             \t|  0.01374        \t|  379            \t|  5.2075         \t|  59.853         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                       \t|  0.0065194      \t|  379            \t|  2.4709         \t|  28.399         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                  \t|  0.0060681      \t|  379            \t|  2.2998         \t|  26.433         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                \t|  0.0019216      \t|  379            \t|  0.72827        \t|  8.3704         \t|\n",
      "|  [LightningModule]LitInstanceNormAE.transfer_batch_to_device                                                                                                   \t|  0.0018596      \t|  379            \t|  0.7048         \t|  8.1006         \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                    \t|  0.0015745      \t|  379            \t|  0.59675        \t|  6.8588         \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                  \t|  0.0011798      \t|  379            \t|  0.44716        \t|  5.1394         \t|\n",
      "|  [LightningModule]LitInstanceNormAE.optimizer_zero_grad                                                                                                        \t|  5.5759e-05     \t|  379            \t|  0.021133       \t|  0.24289        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end      \t|  0.012042       \t|  1              \t|  0.012042       \t|  0.1384         \t|\n",
      "|  [LightningModule]LitInstanceNormAE.configure_gradient_clipping                                                                                                \t|  1.8055e-05     \t|  379            \t|  0.0068429      \t|  0.078649       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end      \t|  1.739e-05      \t|  379            \t|  0.006591       \t|  0.075753       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                      \t|  0.001704       \t|  1              \t|  0.001704       \t|  0.019585       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                \t|  3.1541e-06     \t|  379            \t|  0.0011954      \t|  0.013739       \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                     \t|  2.939e-06      \t|  379            \t|  0.0011139      \t|  0.012802       \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                           \t|  0.0010064      \t|  1              \t|  0.0010064      \t|  0.011567       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                \t|  0.00099164     \t|  1              \t|  0.00099164     \t|  0.011397       \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                 \t|  2.2989e-06     \t|  379            \t|  0.00087129     \t|  0.010014       \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                   \t|  2.0311e-06     \t|  379            \t|  0.00076981     \t|  0.0088478      \t|\n",
      "|  [LightningModule]LitInstanceNormAE.on_before_batch_transfer                                                                                                   \t|  1.6309e-06     \t|  379            \t|  0.00061811     \t|  0.0071043      \t|\n",
      "|  [LightningModule]LitInstanceNormAE.on_after_batch_transfer                                                                                                    \t|  1.6129e-06     \t|  379            \t|  0.0006113      \t|  0.007026       \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                            \t|  1.5946e-06     \t|  379            \t|  0.00060436     \t|  0.0069462      \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                  \t|  1.5716e-06     \t|  379            \t|  0.00059562     \t|  0.0068458      \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                   \t|  1.5079e-06     \t|  379            \t|  0.00057148     \t|  0.0065683      \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                    \t|  1.4695e-06     \t|  379            \t|  0.00055692     \t|  0.006401       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                        \t|  0.00054078     \t|  1              \t|  0.00054078     \t|  0.0062155      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                  \t|  0.00051477     \t|  1              \t|  0.00051477     \t|  0.0059165      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start    \t|  1.3479e-06     \t|  379            \t|  0.00051085     \t|  0.0058715      \t|\n",
      "|  [LightningModule]LitInstanceNormAE.on_train_batch_start                                                                                                       \t|  1.3129e-06     \t|  379            \t|  0.0004976      \t|  0.0057191      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward      \t|  1.2494e-06     \t|  379            \t|  0.00047351     \t|  0.0054423      \t|\n",
      "|  [LightningModule]LitInstanceNormAE.on_train_batch_end                                                                                                         \t|  1.2041e-06     \t|  379            \t|  0.00045634     \t|  0.0052449      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                           \t|  1.0914e-06     \t|  379            \t|  0.00041365     \t|  0.0047542      \t|\n",
      "|  [LightningModule]LitInstanceNormAE.on_before_zero_grad                                                                                                        \t|  1.0533e-06     \t|  379            \t|  0.00039919     \t|  0.0045881      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad     \t|  1.0426e-06     \t|  379            \t|  0.00039514     \t|  0.0045415      \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                      \t|  9.8786e-07     \t|  379            \t|  0.0003744      \t|  0.0043031      \t|\n",
      "|  [LightningModule]LitInstanceNormAE.on_before_backward                                                                                                         \t|  9.8732e-07     \t|  379            \t|  0.0003742      \t|  0.0043008      \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                     \t|  9.673e-07      \t|  379            \t|  0.00036661     \t|  0.0042136      \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                               \t|  9.5836e-07     \t|  379            \t|  0.00036322     \t|  0.0041746      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step\t|  9.3268e-07     \t|  379            \t|  0.00035348     \t|  0.0040628      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward       \t|  9.2709e-07     \t|  379            \t|  0.00035137     \t|  0.0040384      \t|\n",
      "|  [LightningModule]LitInstanceNormAE.on_after_backward                                                                                                          \t|  8.9385e-07     \t|  379            \t|  0.00033877     \t|  0.0038936      \t|\n",
      "|  [LightningModule]LitInstanceNormAE.on_before_optimizer_step                                                                                                   \t|  7.2859e-07     \t|  379            \t|  0.00027613     \t|  0.0031738      \t|\n",
      "|  [LightningModule]LitInstanceNormAE.configure_optimizers                                                                                                       \t|  0.00013761     \t|  1              \t|  0.00013761     \t|  0.0015817      \t|\n",
      "|  [LightningModule]LitInstanceNormAE.lr_scheduler_step                                                                                                          \t|  4.4751e-05     \t|  1              \t|  4.4751e-05     \t|  0.00051435     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                   \t|  2.065e-05      \t|  1              \t|  2.065e-05      \t|  0.00023734     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint      \t|  6.6897e-06     \t|  1              \t|  6.6897e-06     \t|  7.6888e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                          \t|  6.3698e-06     \t|  1              \t|  6.3698e-06     \t|  7.3211e-05     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                   \t|  4.5598e-06     \t|  1              \t|  4.5598e-06     \t|  5.2408e-05     \t|\n",
      "|  [LightningModule]LitInstanceNormAE.on_fit_end                                                                                                                 \t|  4.2696e-06     \t|  1              \t|  4.2696e-06     \t|  4.9073e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                         \t|  3.7597e-06     \t|  1              \t|  3.7597e-06     \t|  4.3213e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                               \t|  3.4003e-06     \t|  1              \t|  3.4003e-06     \t|  3.9081e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                            \t|  3.37e-06       \t|  1              \t|  3.37e-06       \t|  3.8733e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                     \t|  3.3099e-06     \t|  1              \t|  3.3099e-06     \t|  3.8043e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start          \t|  3.2e-06        \t|  1              \t|  3.2e-06        \t|  3.6779e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                  \t|  2.99e-06       \t|  1              \t|  2.99e-06       \t|  3.4366e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                   \t|  2.6398e-06     \t|  1              \t|  2.6398e-06     \t|  3.0341e-05     \t|\n",
      "|  [LightningModule]LitInstanceNormAE.on_train_epoch_start                                                                                                       \t|  2.61e-06       \t|  1              \t|  2.61e-06       \t|  2.9998e-05     \t|\n",
      "|  [LightningModule]LitInstanceNormAE.on_train_start                                                                                                             \t|  2.2799e-06     \t|  1              \t|  2.2799e-06     \t|  2.6204e-05     \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                             \t|  2.2301e-06     \t|  1              \t|  2.2301e-06     \t|  2.5631e-05     \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                               \t|  2.21e-06       \t|  1              \t|  2.21e-06       \t|  2.5401e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end              \t|  2.1202e-06     \t|  1              \t|  2.1202e-06     \t|  2.4368e-05     \t|\n",
      "|  [LightningModule]LitInstanceNormAE.teardown                                                                                                                   \t|  2.1099e-06     \t|  1              \t|  2.1099e-06     \t|  2.425e-05      \t|\n",
      "|  [LightningModule]LitInstanceNormAE.configure_callbacks                                                                                                        \t|  2.1001e-06     \t|  1              \t|  2.1001e-06     \t|  2.4138e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                \t|  2.0098e-06     \t|  1              \t|  2.0098e-06     \t|  2.31e-05       \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                           \t|  1.9399e-06     \t|  1              \t|  1.9399e-06     \t|  2.2297e-05     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                 \t|  1.9199e-06     \t|  1              \t|  1.9199e-06     \t|  2.2067e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start            \t|  1.9097e-06     \t|  1              \t|  1.9097e-06     \t|  2.1949e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                        \t|  1.8398e-06     \t|  1              \t|  1.8398e-06     \t|  2.1146e-05     \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                     \t|  1.5101e-06     \t|  1              \t|  1.5101e-06     \t|  1.7357e-05     \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                  \t|  1.4999e-06     \t|  1              \t|  1.4999e-06     \t|  1.7239e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start    \t|  1.3201e-06     \t|  1              \t|  1.3201e-06     \t|  1.5173e-05     \t|\n",
      "|  [LightningModule]LitInstanceNormAE.on_train_epoch_end                                                                                                         \t|  1.3201e-06     \t|  1              \t|  1.3201e-06     \t|  1.5173e-05     \t|\n",
      "|  [LightningModule]LitInstanceNormAE.prepare_data                                                                                                               \t|  1.3104e-06     \t|  1              \t|  1.3104e-06     \t|  1.5061e-05     \t|\n",
      "|  [LightningModule]LitInstanceNormAE.on_train_end                                                                                                               \t|  1.16e-06       \t|  1              \t|  1.16e-06       \t|  1.3332e-05     \t|\n",
      "|  [LightningModule]LitInstanceNormAE.on_save_checkpoint                                                                                                         \t|  9.9e-07        \t|  1              \t|  9.9e-07        \t|  1.1379e-05     \t|\n",
      "|  [LightningModule]LitInstanceNormAE.on_fit_start                                                                                                               \t|  9.6019e-07     \t|  1              \t|  9.6019e-07     \t|  1.1036e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end            \t|  9.4995e-07     \t|  1              \t|  9.4995e-07     \t|  1.0918e-05     \t|\n",
      "|  [LightningModule]LitInstanceNormAE.configure_sharded_model                                                                                                    \t|  9.2015e-07     \t|  1              \t|  9.2015e-07     \t|  1.0576e-05     \t|\n",
      "|  [LightningModule]LitInstanceNormAE.setup                                                                                                                      \t|  8.8988e-07     \t|  1              \t|  8.8988e-07     \t|  1.0228e-05     \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from lightning.pytorch import Trainer\n",
    "trainer = pl.Trainer(max_epochs=1, devices=[0], profiler='simple')\n",
    "trainer.fit(model=model, train_dataloaders=edge_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
