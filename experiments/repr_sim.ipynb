{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exam the similarity metric difference\n",
    "1. representation cosine\n",
    "2. EL2N\n",
    "3. Grad Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from pynndescent import NNDescent\n",
    "from scipy import stats\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.data import NormalDataProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIS_METHOD = \"DVI\" # DeepVisualInsight\n",
    "CONTENT_PATH = \"/home/xianglin/projects/DVI_data/resnet18_fmnist\"\n",
    "GPU_ID = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(CONTENT_PATH)\n",
    "with open(os.path.join(CONTENT_PATH, \"config.json\"), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config = config[VIS_METHOD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTING = config[\"SETTING\"]\n",
    "CLASSES = config[\"CLASSES\"]\n",
    "DATASET = config[\"DATASET\"]\n",
    "PREPROCESS = config[\"VISUALIZATION\"][\"PREPROCESS\"]\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "LAMBDA1 = VISUALIZATION_PARAMETER[\"LAMBDA1\"]\n",
    "B_N_EPOCHS = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"B_N_EPOCHS\"]\n",
    "L_BOUND = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"L_BOUND\"]\n",
    "ENCODER_DIMS = VISUALIZATION_PARAMETER[\"ENCODER_DIMS\"]\n",
    "DECODER_DIMS = VISUALIZATION_PARAMETER[\"DECODER_DIMS\"]\n",
    "S_N_EPOCHS = VISUALIZATION_PARAMETER[\"S_N_EPOCHS\"]\n",
    "N_NEIGHBORS = VISUALIZATION_PARAMETER[\"N_NEIGHBORS\"]\n",
    "PATIENT = VISUALIZATION_PARAMETER[\"PATIENT\"]\n",
    "MAX_EPOCH = VISUALIZATION_PARAMETER[\"MAX_EPOCH\"]\n",
    "\n",
    "VIS_MODEL_NAME = VISUALIZATION_PARAMETER[\"VIS_MODEL_NAME\"]\n",
    "EVALUATION_NAME = VISUALIZATION_PARAMETER[\"EVALUATION_NAME\"]\n",
    "\n",
    "# Define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model.model as subject_model\n",
    "net = eval(\"subject_model.{}()\".format(NET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initialization...\n"
     ]
    }
   ],
   "source": [
    "# Define data_provider\n",
    "data_provider = NormalDataProvider(CONTENT_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, device=DEVICE, classes=CLASSES, epoch_name=\"Epoch\", verbose=1)\n",
    "if PREPROCESS:\n",
    "    data_provider._meta_data()\n",
    "    if B_N_EPOCHS >0:\n",
    "        data_provider._estimate_boundary(LEN//10, l_bound=L_BOUND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn(train_data):\n",
    "    # number of trees in random projection forest\n",
    "    n_trees = min(64, 5 + int(round((train_data.shape[0]) ** 0.5 / 20.0)))\n",
    "    # max number of nearest neighbor iters to perform\n",
    "    n_iters = max(5, int(round(np.log2(train_data.shape[0]))))\n",
    "    # distance metric\n",
    "    metric = \"cosine\"\n",
    "    # get nearest neighbors\n",
    "    nnd = NNDescent(\n",
    "        train_data,\n",
    "        n_neighbors=2,\n",
    "        metric=metric,\n",
    "        n_trees=n_trees,\n",
    "        n_iters=n_iters,\n",
    "        max_candidates=60,\n",
    "        verbose=False\n",
    "    )\n",
    "    knn_indices, _ = nnd.neighbor_graph\n",
    "    return knn_indices[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 596.50it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 8057.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# compute EL2N\n",
    "prev_e = 1\n",
    "next_e = 20\n",
    "prev_data = data_provider.train_representation(prev_e)\n",
    "next_data = data_provider.train_representation(next_e)\n",
    "train_labels = data_provider.train_labels(prev_e)\n",
    "prev_pw = data_provider.get_pred(next_e, prev_data)\n",
    "next_pw = data_provider.get_pred(next_e, next_data)\n",
    "y = np.eye(np.max(train_labels)+1)[train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest sample in spatial (el2n)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0015935003091235537, 0.27605884758999644, 2.3590392961292395e-07, 48088)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_el2n = next_pw-y\n",
    "indices = nn(next_el2n)\n",
    "closest_el2n = next_el2n[indices]\n",
    "print(\"Closest sample in spatial (el2n)\")\n",
    "closest_el2n_sim = np.array([distance.cosine(closest_el2n[i], next_el2n[i]) for i in range(len(prev_data))])\n",
    "# closest_el2n_sim = np.array([distance.euclidean(closest_el2n[i], next_el2n[i]) for i in range(len(prev_data))])\n",
    "closest_el2n_sim.mean(), closest_el2n_sim.max(), closest_el2n_sim.min(), np.sum(closest_el2n_sim<closest_el2n_sim.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest sample in spatial (repr)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.009428476477309267, 0.20775940969782503, 2.5229753518596354e-06, 41043)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = nn(next_data)\n",
    "closest_repr = next_data[indices]\n",
    "print(\"Closest sample in spatial (repr)\")\n",
    "closest_repr_sim = np.array([distance.cosine(closest_repr[i], next_data[i]) for i in range(len(prev_data))])\n",
    "# closest_repr_sim_eu = np.array([distance.euclidean(closest_repr[i], next_data[i]) for i in range(len(prev_data))])\n",
    "closest_repr_sim.mean(), closest_repr_sim.max(), closest_repr_sim.min(), np.sum(closest_repr_sim<closest_repr_sim.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.912433547374783, pvalue=0.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.spearmanr(closest_repr_sim, closest_el2n_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal EL2N\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.17452833456570768, 1.819032124194774, 0.0035188219099987483, 39718)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_el2n = prev_pw-y\n",
    "next_el2n = next_pw-y\n",
    "print(\"Temporal EL2N\")\n",
    "el2n_sim = np.array([distance.cosine(prev_el2n[i], next_el2n[i]) for i in range(len(prev_data))])\n",
    "el2n_sim.mean(), el2n_sim.max(), el2n_sim.min(), np.sum(el2n_sim<el2n_sim.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal repr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4391693970449143, 0.7961366576427347, 0.24475687000959534, 32313)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Temporal repr\")\n",
    "repr_sim = np.array([distance.cosine(prev_data[i], next_data[i]) for i in range(len(prev_data))])\n",
    "repr_sim_eu = np.array([distance.euclidean(prev_data[i], next_data[i]) for i in range(len(prev_data))])\n",
    "repr_sim.mean(), repr_sim.max(), repr_sim.min(), np.sum(repr_sim<repr_sim.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=0.8296277051350633, pvalue=0.0),\n",
       " SpearmanrResult(correlation=-0.24715577499998778, pvalue=0.0))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.spearmanr(repr_sim, el2n_sim), stats.spearmanr(repr_sim_eu, el2n_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(train_data):\n",
    "    train_max = train_data.max(axis=0)\n",
    "    train_min = train_data.min(axis=0)\n",
    "    train_data = (train_data - train_max)/(train_max-train_min)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_prev_data = normalize_data(prev_data)\n",
    "norm_next_data = normalize_data(next_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4391693970449143,\n",
       " 0.24475687000959534,\n",
       " 0.7961366576427347,\n",
       " 1.4239227826200804,\n",
       " 1.271736745293891,\n",
       " 1.7340846400093302)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_sim = np.array([distance.cosine(prev_data[i], next_data[i]) for i in range(len(prev_data))])\n",
    "norm_spatial_sim = np.array([distance.cosine(norm_prev_data[i], next_data[i]) for i in range(len(prev_data))])\n",
    "spatial_sim.mean(), spatial_sim.min(), spatial_sim.max(),norm_spatial_sim.mean(), norm_spatial_sim.min(), norm_spatial_sim.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.5018379568282328, pvalue=0.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.spearmanr(spatial_sim, norm_spatial_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.009428476477309267,\n",
       " 0.20775940969782503,\n",
       " 2.5229753518596354e-06,\n",
       " 0.0007488045515802833,\n",
       " 0.010259779776457867,\n",
       " 2.2740853933278515e-07)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_closest_repr = norm_next_data[indices]\n",
    "spatial_repr_sim = np.array([distance.cosine(closest_repr[i], next_data[i]) for i in range(len(prev_data))])\n",
    "norm_spatial_repr_sim = np.array([distance.cosine(norm_closest_repr[i], norm_next_data[i]) for i in range(len(prev_data))])\n",
    "spatial_repr_sim.mean(), spatial_repr_sim.max(), spatial_repr_sim.min(), norm_spatial_repr_sim.mean(), norm_spatial_repr_sim.max(), norm_spatial_repr_sim.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.9534619224490111, pvalue=0.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.spearmanr(spatial_repr_sim, norm_spatial_repr_sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
