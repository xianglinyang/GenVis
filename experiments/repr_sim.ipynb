{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exam the similarity metric difference\n",
    "1. representation cosine\n",
    "2. EL2N\n",
    "3. Grad Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from scipy import stats\n",
    "from scipy.special import softmax\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from singleVis.data import NormalDataProvider\n",
    "from singleVis.utils import find_neighbor_preserving_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIS_METHOD = \"tDVI\" # DeepVisualInsight\n",
    "CONTENT_PATH = \"/home/xianglin/projects/DVI_data/resnet18_mnist\"\n",
    "GPU_ID = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(CONTENT_PATH)\n",
    "with open(os.path.join(CONTENT_PATH, \"config.json\"), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config = config[VIS_METHOD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTING = config[\"SETTING\"]\n",
    "CLASSES = config[\"CLASSES\"]\n",
    "DATASET = config[\"DATASET\"]\n",
    "PREPROCESS = config[\"VISUALIZATION\"][\"PREPROCESS\"]\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "VIS_MODEL = VISUALIZATION_PARAMETER['VIS_MODEL']\n",
    "LAMBDA1 = VISUALIZATION_PARAMETER[\"LAMBDA1\"]\n",
    "B_N_EPOCHS = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"B_N_EPOCHS\"]\n",
    "L_BOUND = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"L_BOUND\"]\n",
    "ENCODER_DIMS = VISUALIZATION_PARAMETER[\"ENCODER_DIMS\"]\n",
    "DECODER_DIMS = VISUALIZATION_PARAMETER[\"DECODER_DIMS\"]\n",
    "S_N_EPOCHS = VISUALIZATION_PARAMETER[\"S_N_EPOCHS\"]\n",
    "N_NEIGHBORS = VISUALIZATION_PARAMETER[\"N_NEIGHBORS\"]\n",
    "PATIENT = VISUALIZATION_PARAMETER[\"PATIENT\"]\n",
    "MAX_EPOCH = VISUALIZATION_PARAMETER[\"MAX_EPOCH\"]\n",
    "\n",
    "VIS_MODEL_NAME = VISUALIZATION_PARAMETER[\"VIS_MODEL_NAME\"]\n",
    "EVALUATION_NAME = VISUALIZATION_PARAMETER[\"EVALUATION_NAME\"]\n",
    "\n",
    "# Define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIS_MODEL_NAME = \"tDVI_baseAE\"\n",
    "EVALUATION_NAME = \"evaluation_tDVI_baseAE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model.model as subject_model\n",
    "net = eval(\"subject_model.{}()\".format(NET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initialization...\n"
     ]
    }
   ],
   "source": [
    "# Define data_provider\n",
    "data_provider = NormalDataProvider(CONTENT_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, device=DEVICE, classes=CLASSES, epoch_name=\"Epoch\", verbose=1)\n",
    "if PREPROCESS:\n",
    "    data_provider._meta_data()\n",
    "    if B_N_EPOCHS >0:\n",
    "        data_provider._estimate_boundary(LEN//10, l_bound=L_BOUND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define semantic change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_diff(prev_e, next_e, x, target, data_provider, criterion):\n",
    "\n",
    "    model_t = data_provider.model_function(prev_e)\n",
    "    model_t = model_t.to(DEVICE)\n",
    "    optimizer = optim.SGD(model_t.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    # Forward pass and compute gradients at time t\n",
    "    output_t = model_t(x)\n",
    "    loss_t = criterion(output_t, target)\n",
    "    optimizer.zero_grad()\n",
    "    loss_t.backward()\n",
    "\n",
    "    # Save gradients at time t\n",
    "    grads_t = [p.grad.clone() for p in model_t.parameters()]\n",
    "\n",
    "\n",
    "    model_t1 = data_provider.model_function(next_e)\n",
    "    model_t1 = model_t1.to(DEVICE)\n",
    "    optimizer = optim.SGD(model_t1.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "    # Forward pass and compute gradients at time t+1\n",
    "    output_t1 = model_t1(x)\n",
    "    loss_t1 = criterion(output_t1, target)\n",
    "    optimizer.zero_grad()\n",
    "    loss_t1.backward()\n",
    "\n",
    "    # Save gradients at time t+1\n",
    "    grads_t1 = [p.grad.clone() for p in model_t1.parameters()]\n",
    "\n",
    "    # Compute cosine similarity between gradients at t and t+1\n",
    "    cos_sim_values = []\n",
    "    cos = nn.CosineSimilarity(dim=0)\n",
    "    for g_t, g_t1 in zip(grads_t, grads_t1):\n",
    "        cos_sim = cos(g_t.flatten(), g_t1.flatten())\n",
    "        cos_sim_values.append(cos_sim.item())\n",
    "\n",
    "    # Average cosine similarity\n",
    "    avg_cos_sim = sum(cos_sim_values) / len(cos_sim_values)\n",
    "\n",
    "    # Compute cosine distance\n",
    "    cos_dist = 1 - avg_cos_sim\n",
    "\n",
    "    # print(f\"Cosine Distance: {cos_dist}\")\n",
    "    return cos_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_e = 13\n",
    "next_e = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "training_data = data_provider._training_data()\n",
    "targets = data_provider.train_labels(prev_e)\n",
    "\n",
    "test_len = 100\n",
    "idxs = np.random.choice(len(training_data), test_len, replace=False)\n",
    "\n",
    "dists = np.zeros(test_len)\n",
    "for i in range(test_len):\n",
    "    x = training_data[idxs[i]:idxs[i]+1]\n",
    "    y = torch.from_numpy(targets[idxs[i]:idxs[i]+1]).to(DEVICE)\n",
    "    dist = gradient_diff(prev_e, next_e, x, y, data_provider, criterion)\n",
    "    dists[i] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 6794.23it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 6559.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# compute EL2N\n",
    "prev_data = data_provider.train_representation(prev_e)\n",
    "next_data = data_provider.train_representation(next_e)\n",
    "train_labels = data_provider.train_labels(prev_e)\n",
    "prev_pw = data_provider.get_pred(next_e, prev_data)\n",
    "next_pw = data_provider.get_pred(next_e, next_data)\n",
    "y = np.eye(np.max(train_labels)+1)[train_labels]\n",
    "\n",
    "prev_pw = softmax(prev_pw, axis=1)\n",
    "next_pw = softmax(next_pw, axis=1)\n",
    "prev_el2n = prev_pw-y\n",
    "next_el2n = next_pw-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal repr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PearsonRResult(statistic=-0.23657691998611244, pvalue=0.017799136928073844),\n",
       " PearsonRResult(statistic=-0.1330303782189574, pvalue=0.18701824340591475))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Temporal repr\")\n",
    "repr_dists = np.array([distance.cosine(prev_data[idxs[i]], next_data[idxs[i]]) for i in range(len(idxs))])\n",
    "repr_dists_eu = np.array([distance.euclidean(prev_data[idxs[i]], next_data[idxs[i]]) for i in range(len(idxs))])\n",
    "stats.pearsonr(repr_dists, dists), stats.pearsonr(repr_dists_eu, dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=-0.13060886087056184, pvalue=0.1952430285675027)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z-score similarity calculation\n",
    "from scipy import stats\n",
    "prev_norm = stats.zscore(prev_data)\n",
    "next_norm = stats.zscore(next_data)\n",
    "norm_repr_dists_eu = np.array([distance.euclidean(prev_norm[idxs[i]], next_norm[idxs[i]]) for i in range(len(idxs))])\n",
    "stats.pearsonr(norm_repr_dists_eu, dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # neighbor preserving rate\n",
    "# npr_eu = find_neighbor_preserving_rate(prev_data[idxs], next_data[idxs], n_neighbors=15, metric=\"euclidean\")\n",
    "# npr_cosine = find_neighbor_preserving_rate(prev_data[idxs], next_data[idxs], n_neighbors=15, metric=\"cosine\")\n",
    "# stats.spearmanr(npr_eu, dists), stats.spearmanr(npr_cosine, dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "training_data = data_provider._training_data()\n",
    "targets = data_provider.train_labels(1)\n",
    "\n",
    "test_len = 10\n",
    "idxs = np.random.choice(len(training_data), test_len, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = training_data[idxs]\n",
    "labels = torch.from_numpy(targets[idxs]).to(DEVICE)\n",
    "\n",
    "start = data_provider.s\n",
    "end = data_provider.e\n",
    "period = data_provider.p\n",
    "LEN = len(idxs)\n",
    "EPOCH = (end - start) // period + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41953571, 0.27321391, 0.24926051, 0.27854855, 0.36799557,\n",
       "        0.42341644, 0.38818385, 0.36316491, 0.58657772, 0.50273828,\n",
       "        0.25421803, 0.17575124, 0.09855688, 0.06827186],\n",
       "       [0.39179168, 0.26227702, 0.2909557 , 0.29576715, 0.35235029,\n",
       "        0.43536029, 0.3941605 , 0.34470697, 0.32502916, 0.31006617,\n",
       "        0.24018108, 0.16255178, 0.08585598, 0.07388178],\n",
       "       [0.32083815, 0.26364554, 0.23442972, 0.26694593, 0.30454997,\n",
       "        0.34250334, 0.41704744, 0.40726463, 0.3643499 , 0.28702517,\n",
       "        0.17327915, 0.16932114, 0.0846475 , 0.04831351],\n",
       "       [0.30103821, 0.27762048, 0.27158107, 0.3089407 , 0.27938881,\n",
       "        0.50409725, 0.4930542 , 0.30367474, 0.49879786, 0.40805532,\n",
       "        0.23286593, 0.18255562, 0.11210328, 0.0729455 ],\n",
       "       [0.42239682, 0.26496278, 0.24439643, 0.23824394, 0.29390182,\n",
       "        0.36091006, 0.36284533, 0.35847531, 0.38422423, 0.41403395,\n",
       "        0.23063892, 0.14810225, 0.09806933, 0.06349607],\n",
       "       [0.37134237, 0.31097241, 0.24672422, 0.25207221, 0.27622184,\n",
       "        0.43487815, 0.4508093 , 0.38461446, 0.43531669, 0.34617641,\n",
       "        0.21282968, 0.18505573, 0.10865171, 0.06578507],\n",
       "       [0.4629431 , 0.26906284, 0.33346723, 0.31249552, 0.25213858,\n",
       "        0.29398642, 0.34146664, 0.36493784, 0.43196816, 0.36772996,\n",
       "        0.25270192, 0.15447815, 0.08046857, 0.04592131],\n",
       "       [0.38064565, 0.263912  , 0.25585717, 0.29597961, 0.30932313,\n",
       "        0.37214039, 0.37506565, 0.34043873, 0.3772556 , 0.30391785,\n",
       "        0.24594142, 0.18731882, 0.11896021, 0.08169082],\n",
       "       [0.3495208 , 0.30745788, 0.28544329, 0.33573198, 0.39178669,\n",
       "        0.37456866, 0.35114888, 0.33751084, 0.30448043, 0.31518329,\n",
       "        0.18988727, 0.14501502, 0.08958432, 0.06806614],\n",
       "       [0.35691908, 0.31326678, 0.26834481, 0.28885275, 0.324163  ,\n",
       "        0.31707172, 0.40728608, 0.33055849, 0.39233219, 0.40223047,\n",
       "        0.23118957, 0.13691835, 0.12340966, 0.07844692]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_diff = np.zeros((test_len, EPOCH-1))\n",
    "for i in range(test_len):\n",
    "    for prev_e, next_e in zip(range(start, EPOCH), range(start+period,EPOCH+1)):\n",
    "        cos_diff = gradient_diff(prev_e, next_e, data[i:i+1], labels[i:i+1], data_provider, criterion)\n",
    "        high_diff[i, prev_e-1] = cos_diff\n",
    "high_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 16:17:46.255031: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-29 16:17:46.730767: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from singleVis.projector import DVIProjector\n",
    "from singleVis.vis_models import vis_models as vmodels\n",
    "VIS_MODEL_NAME = \"tDVI_baseAE\"\n",
    "EVALUATION_NAME = \"evaluation_singleDVI_baseAE\"\n",
    "VIS_MODEL = \"baseAE\"\n",
    "model = vmodels[VIS_MODEL](ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = DVIProjector(vis_model=model, content_path=CONTENT_PATH, vis_model_name=VIS_MODEL_NAME, epoch_name=\"Epoch\", device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singleVis.projector import tfDVIProjector\n",
    "flag = \"_temporal_id_withoutB\"\n",
    "projector = tfDVIProjector(CONTENT_PATH, flag=flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singleVis.projector import TimeVisProjector\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "ENCODER_DIMS = [512,256,256,256,256,256,2]\n",
    "DECODER_DIMS = [2,256,256,256,256,256,512]\n",
    "ENCODER_DIMS = [512,256,2]\n",
    "DECODER_DIMS = [2,256,512]\n",
    "VIS_MODEL_NAME = \"timevis\"\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = TimeVisProjector(vis_model=model, content_path=CONTENT_PATH, vis_model_name=VIS_MODEL_NAME, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xianglin/projects/DVI_data/resnet18_mnist/Model/Epoch_1/tDVI_baseAE.pth\n",
      "Successfully load the DVI visualization model for iteration 1\n",
      "/home/xianglin/projects/DVI_data/resnet18_mnist/Model/Epoch_2/tDVI_baseAE.pth\n",
      "Successfully load the DVI visualization model for iteration 2\n",
      "/home/xianglin/projects/DVI_data/resnet18_mnist/Model/Epoch_3/tDVI_baseAE.pth\n",
      "Successfully load the DVI visualization model for iteration 3\n",
      "/home/xianglin/projects/DVI_data/resnet18_mnist/Model/Epoch_4/tDVI_baseAE.pth\n",
      "Successfully load the DVI visualization model for iteration 4\n",
      "/home/xianglin/projects/DVI_data/resnet18_mnist/Model/Epoch_5/tDVI_baseAE.pth\n",
      "Successfully load the DVI visualization model for iteration 5\n",
      "/home/xianglin/projects/DVI_data/resnet18_mnist/Model/Epoch_6/tDVI_baseAE.pth\n",
      "Successfully load the DVI visualization model for iteration 6\n",
      "/home/xianglin/projects/DVI_data/resnet18_mnist/Model/Epoch_7/tDVI_baseAE.pth\n",
      "Successfully load the DVI visualization model for iteration 7\n",
      "/home/xianglin/projects/DVI_data/resnet18_mnist/Model/Epoch_8/tDVI_baseAE.pth\n",
      "Successfully load the DVI visualization model for iteration 8\n",
      "/home/xianglin/projects/DVI_data/resnet18_mnist/Model/Epoch_9/tDVI_baseAE.pth\n",
      "Successfully load the DVI visualization model for iteration 9\n",
      "/home/xianglin/projects/DVI_data/resnet18_mnist/Model/Epoch_10/tDVI_baseAE.pth\n",
      "Successfully load the DVI visualization model for iteration 10\n",
      "/home/xianglin/projects/DVI_data/resnet18_mnist/Model/Epoch_11/tDVI_baseAE.pth\n",
      "Successfully load the DVI visualization model for iteration 11\n",
      "/home/xianglin/projects/DVI_data/resnet18_mnist/Model/Epoch_12/tDVI_baseAE.pth\n",
      "Successfully load the DVI visualization model for iteration 12\n",
      "/home/xianglin/projects/DVI_data/resnet18_mnist/Model/Epoch_13/tDVI_baseAE.pth\n",
      "Successfully load the DVI visualization model for iteration 13\n",
      "/home/xianglin/projects/DVI_data/resnet18_mnist/Model/Epoch_14/tDVI_baseAE.pth\n",
      "Successfully load the DVI visualization model for iteration 14\n",
      "/home/xianglin/projects/DVI_data/resnet18_mnist/Model/Epoch_15/tDVI_baseAE.pth\n",
      "Successfully load the DVI visualization model for iteration 15\n"
     ]
    }
   ],
   "source": [
    "low_repr = np.zeros((EPOCH,LEN,2))\n",
    "for i in range(start,end + 1, period):\n",
    "    index = (i - start) //  period\n",
    "    low_repr[index] = projector.batch_project(i, data_provider.train_representation(i)[idxs]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_repr = low_repr.transpose([1,0,2])\n",
    "low_dists = np.linalg.norm(low_repr[:,start//period:,:]-low_repr[:,:(end-period)//period,:], axis=2)\n",
    "low_dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global temporal ranking #train:0.3758241758241759\n"
     ]
    }
   ],
   "source": [
    "corrs = np.zeros(LEN)\n",
    "ps = np.zeros(LEN)\n",
    "for i in range(LEN):\n",
    "    corr, p = stats.spearmanr(high_diff[i], low_dists[i])\n",
    "    corrs[i] = corr\n",
    "    ps[i] = p\n",
    "print(f\"Global temporal ranking #train:{corrs.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DVI: Global temporal ranking #train:0.3147252747252748\n"
     ]
    }
   ],
   "source": [
    "corrs = np.zeros(LEN)\n",
    "ps = np.zeros(LEN)\n",
    "for i in range(LEN):\n",
    "    corr, p = stats.spearmanr(high_diff[i], low_dists[i])\n",
    "    corrs[i] = corr\n",
    "    ps[i] = p\n",
    "print(f\"DVI: Global temporal ranking #train:{corrs.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeVis: Global temporal ranking #train:0.531868131868132\n"
     ]
    }
   ],
   "source": [
    "corrs = np.zeros(LEN)\n",
    "ps = np.zeros(LEN)\n",
    "for i in range(LEN):\n",
    "    corr, p = stats.spearmanr(high_diff[i], low_dists[i])\n",
    "    corrs[i] = corr\n",
    "    ps[i] = p\n",
    "print(f\"TimeVis: Global temporal ranking #train:{corrs.mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
