{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exam the similarity metric difference\n",
    "1. representation cosine\n",
    "2. EL2N\n",
    "3. Grad Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from scipy import stats\n",
    "from scipy.special import softmax\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from singleVis.data import NormalDataProvider\n",
    "from singleVis.utils import find_neighbor_preserving_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIS_METHOD = \"tDVI\" # DeepVisualInsight\n",
    "CONTENT_PATH = \"/home/xianglin/projects/DVI_data/resnet18_mnist\"\n",
    "GPU_ID = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(CONTENT_PATH)\n",
    "with open(os.path.join(CONTENT_PATH, \"config.json\"), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config = config[VIS_METHOD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTING = config[\"SETTING\"]\n",
    "CLASSES = config[\"CLASSES\"]\n",
    "DATASET = config[\"DATASET\"]\n",
    "PREPROCESS = config[\"VISUALIZATION\"][\"PREPROCESS\"]\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "VIS_MODEL = VISUALIZATION_PARAMETER['VIS_MODEL']\n",
    "LAMBDA = VISUALIZATION_PARAMETER[\"LAMBDA\"]\n",
    "B_N_EPOCHS = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"B_N_EPOCHS\"]\n",
    "L_BOUND = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"L_BOUND\"]\n",
    "ENCODER_DIMS = VISUALIZATION_PARAMETER[\"ENCODER_DIMS\"]\n",
    "DECODER_DIMS = VISUALIZATION_PARAMETER[\"DECODER_DIMS\"]\n",
    "S_N_EPOCHS = VISUALIZATION_PARAMETER[\"S_N_EPOCHS\"]\n",
    "N_NEIGHBORS = VISUALIZATION_PARAMETER[\"N_NEIGHBORS\"]\n",
    "PATIENT = VISUALIZATION_PARAMETER[\"PATIENT\"]\n",
    "MAX_EPOCH = VISUALIZATION_PARAMETER[\"MAX_EPOCH\"]\n",
    "\n",
    "VIS_MODEL_NAME = VISUALIZATION_PARAMETER[\"VIS_MODEL_NAME\"]\n",
    "EVALUATION_NAME = VISUALIZATION_PARAMETER[\"EVALUATION_NAME\"]\n",
    "\n",
    "# Define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIS_MODEL_NAME = \"tDVI_baseAE\"\n",
    "EVALUATION_NAME = \"evaluation_tDVI_baseAE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model.model as subject_model\n",
    "net = eval(\"subject_model.{}()\".format(NET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data_provider\n",
    "data_provider = NormalDataProvider(CONTENT_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, device=DEVICE, classes=CLASSES, epoch_name=\"Epoch\", verbose=1)\n",
    "if PREPROCESS:\n",
    "    data_provider._meta_data()\n",
    "    if B_N_EPOCHS >0:\n",
    "        data_provider._estimate_boundary(LEN//10, l_bound=L_BOUND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define semantic change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_diff(prev_e, next_e, x, target, data_provider, criterion):\n",
    "\n",
    "    model_t = data_provider.model_function(prev_e)\n",
    "    model_t = model_t.to(DEVICE)\n",
    "    optimizer = optim.SGD(model_t.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    # Forward pass and compute gradients at time t\n",
    "    output_t = model_t(x)\n",
    "    loss_t = criterion(output_t, target)\n",
    "    optimizer.zero_grad()\n",
    "    loss_t.backward()\n",
    "\n",
    "    # Save gradients at time t\n",
    "    grads_t = [p.grad.clone() for p in model_t.parameters()]\n",
    "\n",
    "\n",
    "    model_t1 = data_provider.model_function(next_e)\n",
    "    model_t1 = model_t1.to(DEVICE)\n",
    "    optimizer = optim.SGD(model_t1.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "    # Forward pass and compute gradients at time t+1\n",
    "    output_t1 = model_t1(x)\n",
    "    loss_t1 = criterion(output_t1, target)\n",
    "    optimizer.zero_grad()\n",
    "    loss_t1.backward()\n",
    "\n",
    "    # Save gradients at time t+1\n",
    "    grads_t1 = [p.grad.clone() for p in model_t1.parameters()]\n",
    "\n",
    "    # Compute cosine similarity between gradients at t and t+1\n",
    "    cos_sim_values = []\n",
    "    cos = nn.CosineSimilarity(dim=0)\n",
    "    for g_t, g_t1 in zip(grads_t, grads_t1):\n",
    "        cos_sim = cos(g_t.flatten(), g_t1.flatten())\n",
    "        cos_sim_values.append(cos_sim.item())\n",
    "\n",
    "    # Average cosine similarity\n",
    "    avg_cos_sim = sum(cos_sim_values) / len(cos_sim_values)\n",
    "\n",
    "    # Compute cosine distance\n",
    "    cos_dist = 1 - avg_cos_sim\n",
    "\n",
    "    # print(f\"Cosine Distance: {cos_dist}\")\n",
    "    return cos_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_e = 13\n",
    "next_e = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "training_data = data_provider._training_data()\n",
    "targets = data_provider.train_labels(prev_e)\n",
    "\n",
    "test_len = 100\n",
    "idxs = np.random.choice(len(training_data), test_len, replace=False)\n",
    "\n",
    "dists = np.zeros(test_len)\n",
    "for i in range(test_len):\n",
    "    x = training_data[idxs[i]:idxs[i]+1]\n",
    "    y = torch.from_numpy(targets[idxs[i]:idxs[i]+1]).to(DEVICE)\n",
    "    dist = gradient_diff(prev_e, next_e, x, y, data_provider, criterion)\n",
    "    dists[i] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute EL2N\n",
    "prev_data = data_provider.train_representation(prev_e)\n",
    "next_data = data_provider.train_representation(next_e)\n",
    "train_labels = data_provider.train_labels(prev_e)\n",
    "prev_pw = data_provider.get_pred(next_e, prev_data)\n",
    "next_pw = data_provider.get_pred(next_e, next_data)\n",
    "y = np.eye(np.max(train_labels)+1)[train_labels]\n",
    "\n",
    "prev_pw = softmax(prev_pw, axis=1)\n",
    "next_pw = softmax(next_pw, axis=1)\n",
    "prev_el2n = prev_pw-y\n",
    "next_el2n = next_pw-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Temporal repr\")\n",
    "repr_dists = np.array([distance.cosine(prev_data[idxs[i]], next_data[idxs[i]]) for i in range(len(idxs))])\n",
    "repr_dists_eu = np.array([distance.euclidean(prev_data[idxs[i]], next_data[idxs[i]]) for i in range(len(idxs))])\n",
    "stats.pearsonr(repr_dists, dists), stats.pearsonr(repr_dists_eu, dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score similarity calculation\n",
    "from scipy import stats\n",
    "prev_norm = stats.zscore(prev_data)\n",
    "next_norm = stats.zscore(next_data)\n",
    "norm_repr_dists_eu = np.array([distance.euclidean(prev_norm[idxs[i]], next_norm[idxs[i]]) for i in range(len(idxs))])\n",
    "stats.pearsonr(norm_repr_dists_eu, dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # neighbor preserving rate\n",
    "# npr_eu = find_neighbor_preserving_rate(prev_data[idxs], next_data[idxs], n_neighbors=15, metric=\"euclidean\")\n",
    "# npr_cosine = find_neighbor_preserving_rate(prev_data[idxs], next_data[idxs], n_neighbors=15, metric=\"cosine\")\n",
    "# stats.spearmanr(npr_eu, dists), stats.spearmanr(npr_cosine, dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "training_data = data_provider._training_data()\n",
    "targets = data_provider.train_labels(1)\n",
    "\n",
    "test_len = 10\n",
    "idxs = np.random.choice(len(training_data), test_len, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = training_data[idxs]\n",
    "labels = torch.from_numpy(targets[idxs]).to(DEVICE)\n",
    "\n",
    "start = data_provider.s\n",
    "end = data_provider.e\n",
    "period = data_provider.p\n",
    "LEN = len(idxs)\n",
    "EPOCH = (end - start) // period + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_diff = np.zeros((test_len, EPOCH-1))\n",
    "for i in range(test_len):\n",
    "    for prev_e, next_e in zip(range(start, EPOCH), range(start+period,EPOCH+1)):\n",
    "        cos_diff = gradient_diff(prev_e, next_e, data[i:i+1], labels[i:i+1], data_provider, criterion)\n",
    "        high_diff[i, prev_e-1] = cos_diff\n",
    "high_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singleVis.projector import DVIProjector\n",
    "from singleVis.vis_models import vis_models as vmodels\n",
    "VIS_MODEL_NAME = \"tDVI_cnAE_sequence\"\n",
    "VIS_MODEL = \"cnAE\"\n",
    "model = vmodels[VIS_MODEL](ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = DVIProjector(vis_model=model, content_path=CONTENT_PATH, vis_model_name=VIS_MODEL_NAME, epoch_name=\"Epoch\", device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singleVis.projector import tfDVIProjector\n",
    "flag = \"_temporal_id_withoutB\"\n",
    "projector = tfDVIProjector(CONTENT_PATH, flag=flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singleVis.projector import TimeVisProjector\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "ENCODER_DIMS = [512,256,256,256,256,256,2]\n",
    "DECODER_DIMS = [2,256,256,256,256,256,512]\n",
    "ENCODER_DIMS = [512,256,2]\n",
    "DECODER_DIMS = [2,256,512]\n",
    "VIS_MODEL_NAME = \"timevis\"\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = TimeVisProjector(vis_model=model, content_path=CONTENT_PATH, vis_model_name=VIS_MODEL_NAME, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_repr = np.zeros((EPOCH,LEN,2))\n",
    "for i in range(start,end + 1, period):\n",
    "    index = (i - start) //  period\n",
    "    low_repr[index] = projector.batch_project(i, data_provider.train_representation(i)[idxs]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_repr = low_repr.transpose([1,0,2])\n",
    "low_dists = np.linalg.norm(low_repr[:,start//period:,:]-low_repr[:,:(end-period)//period,:], axis=2)\n",
    "low_dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = np.zeros(LEN)\n",
    "ps = np.zeros(LEN)\n",
    "for i in range(LEN):\n",
    "    corr, p = stats.spearmanr(high_diff[i], low_dists[i])\n",
    "    corrs[i] = corr\n",
    "    ps[i] = p\n",
    "print(f\"Global temporal ranking #train:{corrs.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = np.zeros(LEN)\n",
    "ps = np.zeros(LEN)\n",
    "for i in range(LEN):\n",
    "    corr, p = stats.spearmanr(high_diff[i], low_dists[i])\n",
    "    corrs[i] = corr\n",
    "    ps[i] = p\n",
    "print(f\"DVI: Global temporal ranking #train:{corrs.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = np.zeros(LEN)\n",
    "ps = np.zeros(LEN)\n",
    "for i in range(LEN):\n",
    "    corr, p = stats.spearmanr(high_diff[i], low_dists[i])\n",
    "    corrs[i] = corr\n",
    "    ps[i] = p\n",
    "print(f\"TimeVis: Global temporal ranking #train:{corrs.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singleVis.eval.evaluator import Evaluator\n",
    "from singleVis.eval.evaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singleVis.projector import tfDVIProjector\n",
    "projector = tfDVIProjector(CONTENT_PATH, flag)\n",
    "evaluator = Evaluator(data_provider, projector, metric=\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singleVis.projector import TimeVisProjector\n",
    "projector = TimeVisProjector(vis_model=model, content_path=CONTENT_PATH, vis_model_name=VIS_MODEL_NAME, device=DEVICE)\n",
    "evaluator = Evaluator(data_provider, projector, metric=\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singleVis.projector import DVIProjector\n",
    "VIS_MODEL_NAME = \"tDVI_baseAE\"\n",
    "VIS_MODEL = \"bnAE\"\n",
    "from singleVis.vis_models import vis_models as vmodels\n",
    "model = vmodels[VIS_MODEL](ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = DVIProjector(vis_model=model, content_path=CONTENT_PATH, vis_model_name=VIS_MODEL_NAME, epoch_name=\"Epoch\", device=DEVICE)\n",
    "evaluator = Evaluator(data_provider,projector, metric=\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singleVis.projector import DVIProjector\n",
    "VIS_MODEL_NAME = \"tDVI_cnAE\"\n",
    "# EVALUATION_NAME = \"evaluation_singleDVI_baseAE\"\n",
    "VIS_MODEL = \"cnAE\"\n",
    "model = vmodels[VIS_MODEL](ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = DVIProjector(vis_model=model, content_path=CONTENT_PATH, vis_model_name=VIS_MODEL_NAME, epoch_name=\"Epoch\", device=DEVICE)\n",
    "evaluator = Evaluator(data_provider,projector, metric=\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.zeros(15)\n",
    "for i in range(1, 16):\n",
    "    p[i-1] = evaluator.eval_temporal_nn_test(i, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "n_neighbors = 3\n",
    "epoch_num = (data_provider.e - data_provider.s) // data_provider.p + 1\n",
    "l = data_provider.test_num\n",
    "high_dists = np.zeros((l, epoch_num))\n",
    "low_dists = np.zeros((l, epoch_num))\n",
    "\n",
    "curr_data = data_provider.test_representation(epoch)\n",
    "curr_embedding = projector.batch_project(epoch, curr_data)\n",
    "\n",
    "for t in range(epoch_num):\n",
    "    data = data_provider.test_representation(t * data_provider.p + data_provider.s)\n",
    "    embedding = projector.batch_project(t * data_provider.p + data_provider.s, data)\n",
    "\n",
    "    high_dist = evaluate_embedding_distance(data, curr_data, metric=\"euclidean\", one_target=False)\n",
    "    low_dist = evaluate_embedding_distance(embedding, curr_embedding, metric=\"euclidean\", one_target=False)\n",
    "    high_dists[:, t] = high_dist\n",
    "    low_dists[:, t] = low_dist\n",
    "\n",
    "# find the index of top k dists\n",
    "# argsort descent order\n",
    "high_orders = np.argsort(high_dists, axis=1)\n",
    "low_orders = np.argsort(low_dists, axis=1)\n",
    "\n",
    "high_rankings = high_orders[:, 1:n_neighbors+1]\n",
    "low_rankings = low_orders[:, 1:n_neighbors+1]\n",
    "\n",
    "corr = np.zeros(len(high_dists))\n",
    "for i in range(len(data)):\n",
    "    corr[i] = len(np.intersect1d(high_rankings[i], low_rankings[i]))\n",
    "print(corr.mean())1] = evaluator.eval_temporal_nn_test(i, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
