{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exam the similarity metric difference\n",
    "1. representation cosine\n",
    "2. EL2N\n",
    "3. Grad Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from scipy import stats\n",
    "from scipy.special import softmax\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from singleVis.data import NormalDataProvider\n",
    "from singleVis.utils import find_neighbor_preserving_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIS_METHOD = \"DVI\" # DeepVisualInsight\n",
    "CONTENT_PATH = \"/home/xianglin/projects/DVI_data/resnet18_mnist\"\n",
    "GPU_ID = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(CONTENT_PATH)\n",
    "with open(os.path.join(CONTENT_PATH, \"config.json\"), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config = config[VIS_METHOD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTING = config[\"SETTING\"]\n",
    "CLASSES = config[\"CLASSES\"]\n",
    "DATASET = config[\"DATASET\"]\n",
    "PREPROCESS = config[\"VISUALIZATION\"][\"PREPROCESS\"]\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "LAMBDA1 = VISUALIZATION_PARAMETER[\"LAMBDA1\"]\n",
    "B_N_EPOCHS = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"B_N_EPOCHS\"]\n",
    "L_BOUND = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"L_BOUND\"]\n",
    "ENCODER_DIMS = VISUALIZATION_PARAMETER[\"ENCODER_DIMS\"]\n",
    "DECODER_DIMS = VISUALIZATION_PARAMETER[\"DECODER_DIMS\"]\n",
    "S_N_EPOCHS = VISUALIZATION_PARAMETER[\"S_N_EPOCHS\"]\n",
    "N_NEIGHBORS = VISUALIZATION_PARAMETER[\"N_NEIGHBORS\"]\n",
    "PATIENT = VISUALIZATION_PARAMETER[\"PATIENT\"]\n",
    "MAX_EPOCH = VISUALIZATION_PARAMETER[\"MAX_EPOCH\"]\n",
    "\n",
    "VIS_MODEL_NAME = VISUALIZATION_PARAMETER[\"VIS_MODEL_NAME\"]\n",
    "EVALUATION_NAME = VISUALIZATION_PARAMETER[\"EVALUATION_NAME\"]\n",
    "\n",
    "# Define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model.model as subject_model\n",
    "net = eval(\"subject_model.{}()\".format(NET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initialization...\n"
     ]
    }
   ],
   "source": [
    "# Define data_provider\n",
    "data_provider = NormalDataProvider(CONTENT_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, device=DEVICE, classes=CLASSES, epoch_name=\"Epoch\", verbose=1)\n",
    "if PREPROCESS:\n",
    "    data_provider._meta_data()\n",
    "    if B_N_EPOCHS >0:\n",
    "        data_provider._estimate_boundary(LEN//10, l_bound=L_BOUND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define semantic change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_e = 14\n",
    "next_e = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_diff(prev_e, next_e, x, target, data_provider, criterion, optimizer):\n",
    "\n",
    "    model_t = data_provider.model_function(prev_e)\n",
    "    model_t = model_t.to(DEVICE)\n",
    "\n",
    "    # Forward pass and compute gradients at time t\n",
    "    output_t = model_t(x)\n",
    "    loss_t = criterion(output_t, target)\n",
    "    optimizer.zero_grad()\n",
    "    loss_t.backward()\n",
    "\n",
    "    # Save gradients at time t\n",
    "    grads_t = [p.grad.clone() for p in model_t.parameters()]\n",
    "\n",
    "    # Simulate some training (just one step for illustration)\n",
    "    optimizer.step()\n",
    "\n",
    "    model_t1 = data_provider.model_function(next_e)\n",
    "    model_t1 = model_t1.to(DEVICE)\n",
    "    # Forward pass and compute gradients at time t+1\n",
    "    output_t1 = model_t1(x)\n",
    "    loss_t1 = criterion(output_t1, target)\n",
    "    optimizer.zero_grad()\n",
    "    loss_t1.backward()\n",
    "\n",
    "    # Save gradients at time t+1\n",
    "    grads_t1 = [p.grad.clone() for p in model_t1.parameters()]\n",
    "\n",
    "    # Compute cosine similarity between gradients at t and t+1\n",
    "    cos_sim_values = []\n",
    "    cos = nn.CosineSimilarity(dim=0)\n",
    "    for g_t, g_t1 in zip(grads_t, grads_t1):\n",
    "        cos_sim = cos(g_t.flatten(), g_t1.flatten())\n",
    "        cos_sim_values.append(cos_sim.item())\n",
    "\n",
    "    # Average cosine similarity\n",
    "    avg_cos_sim = sum(cos_sim_values) / len(cos_sim_values)\n",
    "\n",
    "    # Compute cosine distance\n",
    "    cos_dist = 1 - avg_cos_sim\n",
    "\n",
    "    # print(f\"Cosine Distance: {cos_dist}\")\n",
    "    return cos_dist, loss_t1.item()-loss_t.item(), 1- np.array(cos_sim_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate(prev_el2n,next_el2n,prev_data, next_data, idx):\n",
    "    esti_p = np.dot(prev_el2n[idx][:,np.newaxis],prev_data[idx][None,:]).flatten()\n",
    "    esti_n = np.dot(next_el2n[idx][:,np.newaxis],next_data[idx][None,:]).flatten()\n",
    "    dist = distance.cosine(esti_p, esti_n)\n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "training_data = data_provider._training_data()\n",
    "targets = data_provider.train_labels(prev_e)\n",
    "\n",
    "test_len = 500\n",
    "idxs = np.random.choice(len(training_data), test_len, replace=False)\n",
    "\n",
    "dists = np.zeros(test_len)\n",
    "repr_gradient = np.zeros(test_len)\n",
    "for i in range(test_len):\n",
    "    x = training_data[idxs[i]:idxs[i]+1]\n",
    "    y = torch.from_numpy(targets[idxs[i]:idxs[i]+1]).to(DEVICE)\n",
    "    dist, loss, all_dists = gradient_diff(prev_e, next_e, x, y, data_provider, criterion, optimizer)\n",
    "    dists[i] = dist\n",
    "    repr_gradient[i] = all_dists[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.11986999722237833, pvalue=0.007288922535017365)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.pearsonr(dists, repr_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 7308.04it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 7416.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# compute EL2N\n",
    "prev_data = data_provider.train_representation(prev_e)\n",
    "next_data = data_provider.train_representation(next_e)\n",
    "train_labels = data_provider.train_labels(prev_e)\n",
    "prev_pw = data_provider.get_pred(next_e, prev_data)\n",
    "next_pw = data_provider.get_pred(next_e, next_data)\n",
    "y = np.eye(np.max(train_labels)+1)[train_labels]\n",
    "\n",
    "prev_pw = softmax(prev_pw, axis=1)\n",
    "next_pw = softmax(next_pw, axis=1)\n",
    "prev_el2n = prev_pw-y\n",
    "next_el2n = next_pw-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.11643468987979023, pvalue=0.009163021666833407)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_gradient_dists = np.array([estimate(prev_el2n,next_el2n,prev_data, next_data, idxs[i]) for i in range(len(idxs))])\n",
    "stats.pearsonr(dists, estimated_gradient_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal repr\n"
     ]
    }
   ],
   "source": [
    "print(\"Temporal repr\")\n",
    "repr_dists = np.array([distance.cosine(prev_data[idxs[i]], next_data[idxs[i]]) for i in range(len(idxs))])\n",
    "repr_dists_eu = np.array([distance.euclidean(prev_data[idxs[i]], next_data[idxs[i]]) for i in range(len(idxs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PearsonRResult(statistic=0.13683122187522068, pvalue=0.0021664183521433993),\n",
       " PearsonRResult(statistic=0.26184099581678755, pvalue=2.77627024892479e-09))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.pearsonr(repr_dists, dists), stats.pearsonr(repr_dists_eu, dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # neighbor preserving rate\n",
    "# npr_eu = find_neighbor_preserving_rate(prev_data[idxs], next_data[idxs], n_neighbors=15, metric=\"euclidean\")\n",
    "# npr_cosine = find_neighbor_preserving_rate(prev_data[idxs], next_data[idxs], n_neighbors=15, metric=\"cosine\")\n",
    "# stats.spearmanr(npr_eu, dists), stats.spearmanr(npr_cosine, dists)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
